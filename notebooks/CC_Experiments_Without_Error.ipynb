{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import random as rand\n",
    "import numpy as np\n",
    "import scipy\n",
    "import prior_calc\n",
    "import posterior_calc\n",
    "import collections\n",
    "from networkx.algorithms.traversal.depth_first_search import dfs_tree\n",
    "import tree_generation\n",
    "import data_reader\n",
    "import generate_test_data\n",
    "import tree_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(generate_test_data)\n",
    "# This function assumes that the priors have been already calculated\n",
    "# for the given number of cells and the alpha value. This function performs\n",
    "# exactly 1 experiment in the following steps:\n",
    "# 1) Generate a dataset, with a \"true\" tree (along with ambiguity information)\n",
    "# 2) Construct the posteriors and our inferred tree\n",
    "# 3) Calculate how similar those two trees were, taking ambiguities into account\n",
    "def perform_experiment(num_cells, num_muts, alpha_value, prior_probs):\n",
    "    # Generate \"fake\" data to test\n",
    "    test_generator = generate_test_data.data_generator(num_cells, num_muts, alpha=alpha_value)\n",
    "    test_generator.initialize_Tk()\n",
    "    test_generator.create_lineage_tree()\n",
    "    test_generator.apply_mutations()\n",
    "    test_data = test_generator.return_genotype_data()\n",
    "    true_tree = test_generator.construct_true_mut_tree() # true tree to be used for comparison\n",
    "    true_ambiguities = test_generator.get_ambiguities() # inherent ambiguities in true tree\n",
    "    \n",
    "    # Calculate posteriors and construct the tree\n",
    "    posteriors = posterior_calc.posterior_calculator(test_data, prior_probs, num_cells)\n",
    "    posteriors.calculate_likelihood()\n",
    "    posteriors.calculate_posteriors()\n",
    "    posterior_probabilities = posteriors.return_posteriors()\n",
    "    tree_generator = tree_generation.tree_generation(posterior_probabilities)\n",
    "    inferred_tree = tree_generator.get_min_tree()\n",
    "    \n",
    "    # Compare the true_tree and the inferred_tree and return the similarity score\n",
    "    return tree_comparison.compare_mutation_order(true_tree, inferred_tree, true_ambiguities)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ALPHA=0.3, NUM_CELLS=5, NUM_MUTS3, score =0.91\n",
      "For ALPHA=0.3, NUM_CELLS=5, NUM_MUTS6, score =0.744333333333\n",
      "For ALPHA=0.3, NUM_CELLS=5, NUM_MUTS12, score =0.688651515152\n",
      "For ALPHA=0.3, NUM_CELLS=5, NUM_MUTS19, score =0.634385964912\n",
      "For ALPHA=0.3, NUM_CELLS=10, NUM_MUTS3, score =0.827\n",
      "For ALPHA=0.3, NUM_CELLS=10, NUM_MUTS6, score =0.699133333333\n",
      "For ALPHA=0.3, NUM_CELLS=10, NUM_MUTS12, score =0.557803030303\n",
      "For ALPHA=0.3, NUM_CELLS=10, NUM_MUTS19, score =0.470479532164\n",
      "For ALPHA=0.3, NUM_CELLS=25, NUM_MUTS3, score =0.850333333333\n",
      "For ALPHA=0.3, NUM_CELLS=25, NUM_MUTS6, score =0.699933333333\n",
      "For ALPHA=0.3, NUM_CELLS=25, NUM_MUTS12, score =0.553666666667\n",
      "For ALPHA=0.3, NUM_CELLS=25, NUM_MUTS19, score =0.478333333333\n",
      "For ALPHA=0.3, NUM_CELLS=50, NUM_MUTS3, score =0.918666666667\n",
      "For ALPHA=0.3, NUM_CELLS=50, NUM_MUTS6, score =0.764133333333\n",
      "For ALPHA=0.3, NUM_CELLS=50, NUM_MUTS12, score =0.709575757576\n",
      "For ALPHA=0.3, NUM_CELLS=50, NUM_MUTS19, score =0.65334502924\n",
      "For ALPHA=0.5, NUM_CELLS=5, NUM_MUTS3, score =0.769666666667\n",
      "For ALPHA=0.5, NUM_CELLS=5, NUM_MUTS6, score =0.612133333333\n",
      "For ALPHA=0.5, NUM_CELLS=5, NUM_MUTS12, score =0.438424242424\n",
      "For ALPHA=0.5, NUM_CELLS=5, NUM_MUTS19, score =0.351561403509\n",
      "For ALPHA=0.5, NUM_CELLS=10, NUM_MUTS3, score =0.940333333333\n",
      "For ALPHA=0.5, NUM_CELLS=10, NUM_MUTS6, score =0.763933333333\n",
      "For ALPHA=0.5, NUM_CELLS=10, NUM_MUTS12, score =0.790333333333\n",
      "For ALPHA=0.5, NUM_CELLS=10, NUM_MUTS19, score =0.549461988304\n",
      "For ALPHA=0.5, NUM_CELLS=25, NUM_MUTS3, score =0.772333333333\n",
      "For ALPHA=0.5, NUM_CELLS=25, NUM_MUTS6, score =0.6178\n",
      "For ALPHA=0.5, NUM_CELLS=25, NUM_MUTS12, score =0.4385\n",
      "For ALPHA=0.5, NUM_CELLS=25, NUM_MUTS19, score =0.35583625731\n",
      "For ALPHA=0.5, NUM_CELLS=50, NUM_MUTS3, score =0.94\n",
      "For ALPHA=0.5, NUM_CELLS=50, NUM_MUTS6, score =0.770933333333\n",
      "For ALPHA=0.5, NUM_CELLS=50, NUM_MUTS12, score =0.779303030303\n",
      "For ALPHA=0.5, NUM_CELLS=50, NUM_MUTS19, score =0.554736842105\n",
      "For ALPHA=0.7, NUM_CELLS=5, NUM_MUTS3, score =0.971333333333\n",
      "For ALPHA=0.7, NUM_CELLS=5, NUM_MUTS6, score =0.801\n",
      "For ALPHA=0.7, NUM_CELLS=5, NUM_MUTS12, score =0.723196969697\n",
      "For ALPHA=0.7, NUM_CELLS=5, NUM_MUTS19, score =0.437514619883\n",
      "For ALPHA=0.7, NUM_CELLS=10, NUM_MUTS3, score =0.715\n",
      "For ALPHA=0.7, NUM_CELLS=10, NUM_MUTS6, score =0.548133333333\n",
      "For ALPHA=0.7, NUM_CELLS=10, NUM_MUTS12, score =0.359712121212\n",
      "For ALPHA=0.7, NUM_CELLS=10, NUM_MUTS19, score =0.278748538012\n",
      "For ALPHA=0.7, NUM_CELLS=25, NUM_MUTS3, score =0.714666666667\n",
      "For ALPHA=0.7, NUM_CELLS=25, NUM_MUTS6, score =0.553333333333\n",
      "For ALPHA=0.7, NUM_CELLS=25, NUM_MUTS12, score =0.366818181818\n",
      "For ALPHA=0.7, NUM_CELLS=25, NUM_MUTS19, score =0.280976608187\n",
      "For ALPHA=0.7, NUM_CELLS=50, NUM_MUTS3, score =0.708666666667\n",
      "For ALPHA=0.7, NUM_CELLS=50, NUM_MUTS6, score =0.5504\n",
      "For ALPHA=0.7, NUM_CELLS=50, NUM_MUTS12, score =0.363636363636\n",
      "For ALPHA=0.7, NUM_CELLS=50, NUM_MUTS19, score =0.282210526316\n",
      "For ALPHA=0.9, NUM_CELLS=5, NUM_MUTS3, score =0.996666666667\n",
      "For ALPHA=0.9, NUM_CELLS=5, NUM_MUTS6, score =0.884666666667\n",
      "For ALPHA=0.9, NUM_CELLS=5, NUM_MUTS12, score =0.566924242424\n",
      "For ALPHA=0.9, NUM_CELLS=5, NUM_MUTS19, score =0.474087719298\n",
      "For ALPHA=0.9, NUM_CELLS=10, NUM_MUTS3, score =0.995333333333\n",
      "For ALPHA=0.9, NUM_CELLS=10, NUM_MUTS6, score =0.8876\n",
      "For ALPHA=0.9, NUM_CELLS=10, NUM_MUTS12, score =0.562954545455\n",
      "For ALPHA=0.9, NUM_CELLS=10, NUM_MUTS19, score =0.475187134503\n",
      "For ALPHA=0.9, NUM_CELLS=25, NUM_MUTS3, score =0.671333333333\n",
      "For ALPHA=0.9, NUM_CELLS=25, NUM_MUTS6, score =0.5142\n",
      "For ALPHA=0.9, NUM_CELLS=25, NUM_MUTS12, score =0.319272727273\n",
      "For ALPHA=0.9, NUM_CELLS=25, NUM_MUTS19, score =0.230543859649\n",
      "For ALPHA=0.9, NUM_CELLS=50, NUM_MUTS3, score =0.996\n",
      "For ALPHA=0.9, NUM_CELLS=50, NUM_MUTS6, score =0.8868\n",
      "For ALPHA=0.9, NUM_CELLS=50, NUM_MUTS12, score =0.582651515152\n",
      "For ALPHA=0.9, NUM_CELLS=50, NUM_MUTS19, score =0.473397660819\n"
     ]
    }
   ],
   "source": [
    "# METADATA\n",
    "NUM_CELLS = 6\n",
    "ALPHA = 0.3\n",
    "NUM_MUTS = 4\n",
    "for ALPHA in [0.3, 0.5, 0.7, 0.9]:\n",
    "    for NUM_CELLS in [5, 10, 25, 50]:\n",
    "        # This cell evaluates all the priors without error probabilities\n",
    "        priors_pure = prior_calc.prior_calculator(NUM_CELLS, ALPHA, Btree=100, Bmut=10000)\n",
    "        priors_pure.simulate()\n",
    "        priors_pure.compute_final_probs()\n",
    "        prior_probabilities_pure = priors_pure.return_priors()\n",
    "        \n",
    "        for NUM_MUTS in [3, 6, 12, 19]:\n",
    "            total_score = 0\n",
    "            for trial in range(1000):\n",
    "                total_score += perform_experiment(NUM_CELLS, NUM_MUTS, ALPHA, prior_probabilities_pure)\n",
    "            score = total_score/float(1000)\n",
    "            print 'For ALPHA=' + str(ALPHA) + ', NUM_CELLS=' + str(NUM_CELLS) + ', NUM_MUTS' + str(NUM_MUTS) + ', score =' + str(score)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell evaluates all the priors without error probabilities\n",
    "reload(prior_calc)\n",
    "priors_pure = prior_calc.prior_calculator(NUM_CELLS, ALPHA, Btree=100, Bmut=10000)\n",
    "priors_pure.simulate()\n",
    "priors_pure.compute_final_probs()\n",
    "prior_probabilities_pure = priors_pure.return_priors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = perform_experiment(NUM_CELLS, NUM_MUTS, ALPHA, prior_probabilities_pure)\n",
    "print score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
